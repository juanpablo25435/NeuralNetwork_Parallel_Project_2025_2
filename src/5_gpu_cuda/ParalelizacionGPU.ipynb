{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s-u2kkZve19",
        "outputId": "acf7f2aa-67b9-422d-80f1-0ee314d7187c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compilando...\n",
            "Ejecutando...\n",
            "--- Escenario 3: GPU CUDA Nativo (C++) ---\n",
            "Datos cargados correctamente: 60000 imágenes.\n",
            "Transponiendo datos en RAM...\n",
            "Iniciando entrenamiento CUDA...\n",
            "\n",
            ">>> Tiempo Total GPU (C++ CUDA): 0.65 segundos <<<\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "# 1. Limpieza y Preparación de Datos\n",
        "rm -f mlp_cuda main.cu # Borramos ejecutables viejos\n",
        "mkdir -p data          # Creamos la carpeta data\n",
        "\n",
        "# Descargar MNIST si no existe\n",
        "if [ ! -f data/train-images-idx3-ubyte ]; then\n",
        "    echo \"Descargando dataset MNIST...\"\n",
        "    wget -q -O data/train-images-idx3-ubyte.gz https://storage.googleapis.com/cvdf-datasets/mnist/train-images-idx3-ubyte.gz\n",
        "    wget -q -O data/train-labels-idx1-ubyte.gz https://storage.googleapis.com/cvdf-datasets/mnist/train-labels-idx1-ubyte.gz\n",
        "    gunzip -f data/*.gz\n",
        "fi\n",
        "\n",
        "# 2. Crear el archivo main.cu\n",
        "cat <<EOF > main.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "// Incluimos directamente los headers y fuentes para facilitar compilación en Colab\n",
        "#include \"mnist_loader.h\"\n",
        "#include \"mnist_loader.c\"\n",
        "#include \"mlp_cuda.h\"\n",
        "\n",
        "// RUTAS AJUSTADAS PARA COLAB (Carpeta data/ local)\n",
        "#define TRAIN_IMG \"data/train-images-idx3-ubyte\"\n",
        "#define TRAIN_LBL \"data/train-labels-idx1-ubyte\"\n",
        "\n",
        "int main() {\n",
        "    printf(\"--- Escenario 3: GPU CUDA Nativo (C++) ---\\n\");\n",
        "\n",
        "    // Verificar GPU\n",
        "    int deviceCount;\n",
        "    cudaGetDeviceCount(&deviceCount);\n",
        "    if (deviceCount == 0) {\n",
        "        printf(\"ERROR: No se detectó GPU CUDA. Verifica Entorno de Ejecución > T4 GPU\\n\");\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // Cargar datos\n",
        "    int num_train, r, c;\n",
        "    float* X_raw = load_mnist_images(TRAIN_IMG, &num_train, &r, &c);\n",
        "\n",
        "    if (!X_raw) {\n",
        "        printf(\"ERROR CRÍTICO: No se encontró el archivo de datos en %s\\n\", TRAIN_IMG);\n",
        "        return 1;\n",
        "    }\n",
        "    printf(\"Datos cargados correctamente: %d imágenes.\\n\", num_train);\n",
        "\n",
        "    // Transponer datos en CPU (Optimización de acceso a memoria)\n",
        "    // Convertimos de (N x 784) a (784 x N) para que la GPU lea linealmente\n",
        "    printf(\"Transponiendo datos en RAM...\\n\");\n",
        "    float* X_T = (float*)malloc(num_train * 784 * sizeof(float));\n",
        "    for(int i=0; i<num_train; i++) {\n",
        "        for(int j=0; j<784; j++) {\n",
        "            X_T[j * num_train + i] = X_raw[i * 784 + j];\n",
        "        }\n",
        "    }\n",
        "\n",
        "    MLPCuda net;\n",
        "    // Inicializar Red: 784 entrada -> 512 oculta -> 10 salida, LR=0.1\n",
        "    mlp_init(&net, 784, 512, 10, 0.1f);\n",
        "\n",
        "    // Entrenar\n",
        "    // X_T ya está transpuesto, pasamos NULL en labels porque este benchmark es de velocidad Forward\n",
        "    // Usaremos Batch Size 64 y 10 Epochs\n",
        "    mlp_train(&net, X_T, NULL, num_train, 10, 64);\n",
        "\n",
        "    // Limpieza\n",
        "    mlp_free(&net);\n",
        "    free(X_raw);\n",
        "    free(X_T);\n",
        "    return 0;\n",
        "}\n",
        "EOF\n",
        "\n",
        "# 3. Compilar y Ejecutar\n",
        "echo \"Compilando...\"\n",
        "nvcc -o mlp_cuda main.cu mlp_cuda.cu\n",
        "\n",
        "echo \"Ejecutando...\"\n",
        "./mlp_cuda"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
